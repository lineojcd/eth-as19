{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import sklearn.ensemble\n",
    "import sklearn.metrics\n",
    "import sklearn.datasets\n",
    "import sklearn.model_selection\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##MODEL PARAMETERS\n",
    "###TUNABLE PARAMETERS\n",
    "###imbalance ratio. set to 1.0 for balanced data\n",
    "imbalance_ratio = 1.0\n",
    "###ensemble size\n",
    "ensemble_size = 200\n",
    "###set to None to disable class weights on decision trees\n",
    "tree_class_weight = None#\"balanced\"\n",
    "###which evaluation metric to use. choose between \"AUPRC\", \"AUROC\", and \"Log loss\"\n",
    "\n",
    "#toggle decision tree split optimization criterion\n",
    "criterion = True\n",
    "\n",
    "##SET RANDOM SEED\n",
    "random_state = np.random.RandomState(1973)\n",
    "\n",
    "parameters = {\n",
    "    \"random_state\": random_state,\n",
    "    \"verbose\": 10, #used to keep track of training progress\n",
    "    \"oob_score\": False, #disabled to speed up training for demonstration\n",
    "    \"n_estimators\": ensemble_size,\n",
    "    \"criterion\": \"gini\" if criterion else \"entropy\",\n",
    "    \"class_weight\": tree_class_weight,\n",
    "}\n",
    "param_sets = (\n",
    "    (\"Decision trees\", {\n",
    "        \"max_features\": 1, #NOTE: this should not be done in practice, only set for demonstrational purposed\n",
    "    }),\n",
    "    (\"Decision stumps\", {\n",
    "        \"max_depth\": 1,\n",
    "        \"max_features\": 1,\n",
    "    }),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##DATA PARAMETERS\n",
    "#ratio of first class to second is set to imbalance_ratio \n",
    "class_weights = np.array([imbalance_ratio,1.0],dtype=float)\n",
    "class_weights = (class_weights/np.sum(class_weights)).tolist()\n",
    "\n",
    "#other parameters\n",
    "# NOTE: if n_informative == 35, then there are no uninformative features and the forest of\n",
    "# stumps performs much better\n",
    "data_params = {\n",
    "    \"random_state\": random_state,\n",
    "    \"n_samples\": 10000,\n",
    "    \"n_features\": 40,\n",
    "    \"n_redundant\": 5,\n",
    "    \"n_informative\": 34, #this leaves one uninformative feature\n",
    "    \"n_classes\": 2,\n",
    "    \"weights\": class_weights,\n",
    "}\n",
    "\n",
    "split_params = {\n",
    "    \"random_state\": random_state,\n",
    "    \"test_size\": 0.2,\n",
    "}\n",
    "\n",
    "##GENERATE RANDOM TRAINING DATA\n",
    "X, y = sklearn.datasets.make_classification(**data_params)\n",
    "#training/test split. stratify split by class frequencies\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, stratify=y, **split_params)\n",
    "\n",
    "##MODELS\n",
    "models = dict((\n",
    "    name, \n",
    "    {\"classifier\": sklearn.ensemble.RandomForestClassifier(**parameters, **tree_parameters)},\n",
    ") for name, tree_parameters in param_sets)\n",
    "\n",
    "##TRAINING\n",
    "for name, model in models.items():\n",
    "    #train model\n",
    "    model[\"classifier\"].fit(X_train, y_train)\n",
    "    #predict labels for increasing ensemble sizes\n",
    "    model[\"predict_proba\"] = np.hstack([\n",
    "        tree.predict_proba(X_test)[:,1].reshape(-1,1) for tree in model[\"classifier\"].estimators_\n",
    "    ])\n",
    "    model[\"mean_predict_probas\"] = np.hstack([\n",
    "        np.mean(model[\"predict_proba\"][:,:a],axis=1).reshape(-1,1) for a in range(1, model[\"classifier\"].n_estimators+1)\n",
    "    ])\n",
    "    #scipy.stats.entropy(model[\"predict_proba\"].T)\n",
    "    #evaluate prediction performance\n",
    "    model[\"AUROC\"] = np.array([\n",
    "        sklearn.metrics.roc_auc_score(y_test, subforest) for subforest in model[\"mean_predict_probas\"].T\n",
    "    ])\n",
    "    model[\"AUPRC\"] = np.array([\n",
    "        sklearn.metrics.auc(*(\n",
    "            sklearn.metrics.precision_recall_curve(y_test, subforest)[:-1][::-1]\n",
    "        )) for subforest in model[\"mean_predict_probas\"].T\n",
    "    ])\n",
    "    model[\"Log loss\"] = np.array([\n",
    "            sklearn.metrics.log_loss(y_test, subforest) for subforest in model[\"mean_predict_probas\"].T\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#AU: area under\n",
    "#ROC: receiver operating characteristic curve\n",
    "#PRC: precision-recall curve\n",
    "plot_this = \"AUPRC\"\n",
    "\n",
    "##PLOTTING\n",
    "for name, model in models.items():\n",
    "    plt.plot(model[plot_this], marker=\".\", label=name)\n",
    "\n",
    "#plot labels\n",
    "if plot_this[:2] == \"AU\":\n",
    "    if plot_this == \"AUROC\":\n",
    "        plt.axhline(y=0.5, linestyle=\":\", label=\"Baseline\")\n",
    "        plt.ylabel(\"AUROC\")\n",
    "    elif plot_this == \"AUPRC\":\n",
    "        plt.axhline(y=np.min(class_weights), linestyle=\":\", label=\"Baseline\")\n",
    "        plt.ylabel(\"AUPRC\")\n",
    "else:\n",
    "    plt.ylabel(\"Log loss\")\n",
    "\n",
    "plt.xlabel(\"Size of forest\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
